# **Finding Lane Lines on the Road** 

## Udacity Self-Driving Car NanoDegree
## Project #1

[//]: # (Image References)
[//]: # ([image1]: ./examples/grayscale.jpg "Grayscale")
---
### **Reflection**

### 1. Description of the Pipeline

I like to refer to the code as I explain. I think it is better to understand how the code works this way. It certainly makes my job easier. 
Let's begin. 

#### The Big Picture
My pipeline has the following steps:
```
# Step 0
white_yellow = white_and_yellow(img)
# Step 1
gray = grayscale(white_yellow)
# Step 2
blurry_gray = gaussian_blur(gray, kernel_size)
# Step 3
edges = canny(blurry_gray, low_threshold, high_threshold)
# Step 4
masked_edges = region_of_interest(edges, vertices)
# Step 5
lined_img = hough_lines(masked_edges, rho, theta, threshold, min_line_length, max_line_gap,
                            y_front, y_bottom, x_offset)
# Step 6
w_img = weighted_img(lined_img, img)
```
Now, I am going to explain each step and share more code with you as neccesary. We are not going to be discussing step 0 to step 6 in that exact order, rather I am going to take you through the path I followed. Also, please note that the code snippets used in this write-up are not always complete functions that can be compiled.

#### Step 4
First, we need to be sure what we want to look at, the region of interest. We want just the road in front of us, more specificly the lane we are driving. I really liked the blue line triangle from the "Hough transform" quiz to visualize the region of interest. Used the following code to draw one.
```
mask_lines = np.array([ [[  bottom_left[0],  bottom_left[1],    front_left[0],   front_left[1] ]],
                        [[   front_left[0],   front_left[1],   front_right[0],  front_right[1] ]],
                        [[  front_right[0],  front_right[1],  bottom_right[0], bottom_right[1] ]],
                        [[ bottom_right[0], bottom_right[1],   bottom_left[0],  bottom_left[1] ]] ])

draw_lines(img, mask_lines, color=[0, 0, 255], thickness=4)
```
 ```mask_lines``` is an array of all 4 sides of my polygon. Used the built-in ```draw_lines``` function to finish the job. Now that we madeup our mind on what we want to focus, it's time to science the lane-lines out of this image.
 
#### Steps 1, 2, 3, 5, 6
No customization here. Everything is just as seen in the lessons from the class. Convert the image to ```grayscale``` to facilitate the edge detection. Apply a ```guassian_blur``` to make the job even easier for the ```canny``` function. ```canny``` function is going to take the blurry gray image and find all the edges in it. Because we don't care about all the edges in the world, we use the ```region_of_interest``` function to blackout everything but the pretty polygon we built earlier. The big boss ```hough_lines``` here with all his fancy parameters is going to transform our image into *Hough Space*. In here, all the little points in our edges (thanks to ```canny```) look like intersecting lines. More intersecting lines in *Hough Space* mean more likely that there is a line in the *Image Space*. So, once ```hough_lines``` is done finding all the lines, with little help from ```draw_lines```, a new image is formed with nothing but the small lane-edge-lines. ```Weighted_img``` function takes this new image and superimposes it on to our original image. That's it, job done!

At this point, the first part of the project is completed. Which is to draw small lines on the image indicating the edges of the lane-lines. On to the Part2 aka ```draw_lines``` aka *secret sause*.

#### Step 5.5 aka Draw Lines aka Secret Sauce
Before I throw the code at you, let me give you the big picture. The ```draw_lines``` and other companion functions are implementing the following steps:
1. Filter all the small lines from the output of ```hough_lines``` that doesnt belong on a lane-line.
2. Separate the filtered lines into right-lane lines and left-lane lines.
3. Extract all the points from right-lane lines and left-lane lines into right-lane-points and left-lane-points respectively
4. Perform a *Linear Regression* fit on a given group of points and extrapolate to draw a single line across all the points.
5. Reject the bizzare lines generated by the linear regression.

let's look at the code.
```
# Line filtering and separation
for line in lines:
    for x1,y1,x2,y2 in line:
        # Calculate the slope of the line. yes, avoid divide by zero if you can. 
        m = (y2-y1)/((x2-x1) + 0.0000001)
        
        # Step 1
        # Filter out the lines that are either too horizantal or
        # too vertical to be part of a lane-line
        if abs(m) < 0.5 or abs(m) > 100000:
            continue
        
        # Step 2
        # Separate the right-lane-lines from the left-lane-lines by 
        # using either the slope or where they appear in the image.
        # Lines to the right side of the center are part of the right-lane-line      
        if m > 0 or (x1 > center and x2 > center):
            # Step 3
            right_points.append((x1, y1))
            right_points.append((x2, y2))
        elif m < 0 or (x1 < center and x2 < center):
            # Step 3
            left_points.append((x1, y1))
            left_points.append((x2, y2))

# Linear-Regrassion. Apply on both right_points and left_points
# for a right-lane-line and a left-lane line respectively.
x = np.array(points)[:,[0]]
y = np.array(points)[:,[1]]

# Import and create a regression model
from sklearn import linear_model
reg = linear_model.LinearRegression()

Step 4
# Perform linear regression on our points
reg.fit(x, y)

# Coumpute a score (between 0 and 1, 1 is the best)
# indicating the quality of the fit
score = reg.score(x, y)

# Get the slope and intercept of the line
slope = reg.coef_
intercept = reg.intercept_

# Step 5
# Discard the regression fit unless it is of good quality
if score < 0.9:
    return None

# If the regression fit is of good quality,
# compute the x co-ordinates of the end-points of the line
x1 = int((y_front - intercept) / slope)
x2 = int((y_bottom - intercept) / slope)
return [(x1, y_front), (x2, y_bottom)]
```

#### One more Step
Before you ask, this is the last step. I promise.
So, if the regressionn gave us a bad fit, we throw it out instead of drawing a red line across the image. All good, but what do we do for that frame of the video?
Let's put some choices on the table.
1. Don't draw anything and leave blank.
2. Stay with what we had in the previous frame. Assuming we saved the buffer.
3. Take an average of the last few frames. Huh! why not always display the average of last few frames?

Well, I implemented #2 in the code below. I think #3 might be better though.
Actually, I am in the middle of implementing #3.
```
# Create and initialize the buffer
from collections import deque
line_buffer = deque([])
max_buffer_length = 5

# Fill it with blanks
for i in range(max_buffer_length):
    line_buffer.append([(0, 0), (0, 0)])

# If we got no line from Linear Regression, use the line from before
if line is None:
    line = line_buffer[-1]
else:
    # Check if the buffer is getting full
    if len(line_buffer) >= max_buffer_length:
        line_buffer.popleft()
    # If Linear Regression gave us a line, save a copy for later 
    line_buffer.append(line)
```

#### Step 0
No, I didn't lie. We forgot about this one and no one said a thing.
I did not think about this until I got to the Challenge section. The purpose of this step is to identify white lane-lines and yellow lane-lines more efficiently.

Step 0 overview:
1. Convert the image from RGB to HSV.
2. Create lower and upper limits for white and yellow.
3. Use ```cv2.inRange``` function to create a white mask and a yellow mask.
4. Combine both white and yellow masks.
5. Apply it to the image to blackout everything but white and yellow.
```
def white_and_yellow(img):
    # step 1
    # Convert RGB to HSV
    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
    
    # Step 2
    # Define range of white color in HSV
    white_sens = 15
    lower_white = np.array([0, 0, 255-white_sens])
    upper_white = np.array([180, white_sens, 255])
    
    # Step 2
    # Define range of yellow color in HSV
    yellow = 30
    yellow_sens = 15
    lower_yellow = np.array([yellow - yellow_sens, 100, 50])
    upper_yellow = np.array([yellow + yellow_sens, 255, 255])
    
    # Step 3
    # Threshold the HSV image to get only white colors
    white_mask = cv2.inRange(hsv, lower_white, upper_white)
    # Threshold the HSV image to get only yellow colors
    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
    
    # Step 4
    # Create a single mask for both white and yellow
    white_yellow_mask = cv2.bitwise_or(white_mask, yellow_mask)
    
    # Step 5
    # Bitwise-AND mask and original image
    res = cv2.bitwise_and(img,img, mask= white_yellow_mask)

    # Cake
    return res
```

[//]: # (![alt text][image1])

### 2. Potential shortcomings with the current pipeline

Potential shortcomings are basically the things that can go wrong. Now google *Murphy's Law*.
Let's list them:
1. What happens when we drive on a narrow curvy mountain road? I tuned the region of interest for a straight freeway. So, no/very little road in the region of interest.
2. What if it is too sunny and we are driving on a reflective cement road or what if lanes are not visible for some other reason? The lane lines will be so hard to identify, everything is going to look like a big white blob.
3. Also, the parameters for the ```canny``` function and the ```hough_lines``` function are fixed. We tuned them just for this project. However, in real-world they need to be changing as needed. We are missing a **feedback loop** in our system. 

### 3. Possible improvements to the current pipeline

1. Give it a feedback loop
2. Implement a dynamic region of interest
    - Look down right in front of the car to find the color of the road
    - Use that information to find where the horizen meets the road
    - Record the relative change in slope of the generated lane-lines
    - Monitoring the slope will tell us if the actual lanes on the road are curving
    - Based on this information we can keep refocusing where the road is
3. Better filtering, averaging, and extrapolating of the lines
4. Better tuning of white and yellow masks from Step 0